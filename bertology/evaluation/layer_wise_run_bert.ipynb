{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "bert_path = \"bert-base-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(bert_path)\n",
    "model = BertModel.from_pretrained(bert_path)\n",
    "\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "outputs = model(**inputs, head_mask=torch.tensor([1 for i in range(model.config.num_attention_heads)]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": "SequenceClassifierOutput(loss=tensor(0.7082, grad_fn=<NllLossBackward0>), logits=tensor([[-0.0025, -0.0324]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "outputs": [],
   "source": [
    "class BertForClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BertForClassification, self).__init__()\n",
    "        self.backbone = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "        self.num_heads = self.backbone.config.num_attention_heads\n",
    "        for p in self.parameters():\n",
    "            p.requires_grad = False  # freeze the backbone model\n",
    "        self.linear1 = nn.Linear(768, 256)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.linear2 = nn.Linear(256, 2)  # 2 is the number of classes in this example\n",
    "        self.__hidden_states__()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        head_mask = [0 for _ in range(self.num_heads)]\n",
    "        head_mask_list = []\n",
    "        for i in range(len(head_mask)):\n",
    "            head_mask_n = head_mask[:]\n",
    "            head_mask_n[i] = 1\n",
    "            head_mask_list.append(head_mask_n)\n",
    "        head_mask_list = torch.tensor(head_mask_list)\n",
    "        head_hidden_states = torch.rand(self.num_heads, attention_mask.shape[0],attention_mask.shape[1], 2)\n",
    "        for i in range(len(head_mask_list)):\n",
    "            backbone_n = self.backbone(input_ids, attention_mask=attention_mask, head_mask=head_mask_list[i])\n",
    "            l1 = self.linear1(backbone_n.last_hidden_state)\n",
    "            dropout = self.dropout(l1)\n",
    "            l2 = self.linear2(dropout)\n",
    "            head_hidden_states[i] = l2\n",
    "        return head_hidden_states\n",
    "\n",
    "\n",
    "    def __hidden_states__(self):\n",
    "        backbone = self.backbone(torch.tensor([[1, 1]]), torch.tensor([[1, 1]]), output_hidden_states=True)\n",
    "        self.hidden_states = backbone.hidden_states"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_x = BertForClassification()\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "x = model_x(inputs[\"input_ids\"],inputs[\"attention_mask\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(1)"
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][0][-1].argmax().squeeze()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(1)"
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "labels = torch.tensor([1]).unsqueeze(0)  # Batch size 1\n",
    "\n",
    "labels.squeeze(0).squeeze(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 768])\n",
      "tensor([[205, 115, 300, 229,  48, 242, 115, 308]])\n"
     ]
    }
   ],
   "source": [
    "print(outputs[0].shape)\n",
    "probs = outputs[0]\n",
    "print(torch.argmax(probs,-1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "# layer-wise"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[-0.1144,  0.1937,  0.1250,  ..., -0.3827,  0.2107,  0.5407],\n         [ 0.5308,  0.3207,  0.3665,  ..., -0.0036,  0.7579,  0.0388],\n         [-0.4877,  0.8849,  0.4256,  ..., -0.6976,  0.4458,  0.1231],\n         ...,\n         [-0.7003, -0.1815,  0.3297,  ..., -0.4838,  0.0680,  0.8901],\n         [-1.0355, -0.2567, -0.0317,  ...,  0.3197,  0.3999,  0.1795],\n         [ 0.6080,  0.2610, -0.3131,  ...,  0.0311, -0.6283, -0.1994]]],\n       grad_fn=<NativeLayerNormBackward0>)"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_states = outputs.last_hidden_state\n",
    "last_hidden_states"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[-0.1144,  0.1937,  0.1250,  ..., -0.3827,  0.2107,  0.5407],\n         [ 0.5308,  0.3207,  0.3665,  ..., -0.0036,  0.7579,  0.0388],\n         [-0.4877,  0.8849,  0.4256,  ..., -0.6976,  0.4458,  0.1231],\n         ...,\n         [-0.7003, -0.1815,  0.3297,  ..., -0.4838,  0.0680,  0.8901],\n         [-1.0355, -0.2567, -0.0317,  ...,  0.3197,  0.3999,  0.1795],\n         [ 0.6080,  0.2610, -0.3131,  ...,  0.0311, -0.6283, -0.1994]]],\n       grad_fn=<NativeLayerNormBackward0>)"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_states = outputs.hidden_states\n",
    "hidden_states[-1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<generator object <genexpr> at 0x0000018209B1AE40>]\n"
     ]
    }
   ],
   "source": [
    "layers = []\n",
    "layers.append(hidden_states[i] for i in range(len(hidden_states)))\n",
    "print(layers)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# head-wise"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0],\n        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]])"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head_mask = [0 for _ in range(model.config.num_attention_heads)]\n",
    "head_mask_list = []\n",
    "for i in range(len(head_mask)):\n",
    "    head_mask_n = head_mask[:]\n",
    "    head_mask_n[i] = 1\n",
    "    head_mask_list.append(head_mask_n)\n",
    "head_mask_list = torch.tensor(head_mask_list)\n",
    "head_mask_list"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../../module/bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[-0.5210,  0.0122],\n",
      "         [ 0.1717,  0.1579],\n",
      "         [ 0.2217,  0.1842],\n",
      "         [ 0.4237, -0.0129],\n",
      "         [ 0.3135,  0.8151],\n",
      "         [ 0.1173,  0.1596],\n",
      "         [ 0.0501,  0.0714],\n",
      "         [-0.1485,  0.2781]]], grad_fn=<AddBackward0>), tensor([[[ 0.1059, -0.0953],\n",
      "         [ 0.2949,  0.2448],\n",
      "         [ 0.1185, -0.0947],\n",
      "         [ 0.8020, -0.0554],\n",
      "         [ 0.1865,  0.2868],\n",
      "         [ 0.0678, -0.0389],\n",
      "         [ 0.5599,  0.2315],\n",
      "         [-0.0388,  0.0898]]], grad_fn=<AddBackward0>), tensor([[[-0.2490, -0.1227],\n",
      "         [ 0.8054, -0.1821],\n",
      "         [ 0.3046, -0.3631],\n",
      "         [ 0.7043,  0.2669],\n",
      "         [ 0.3155,  0.6857],\n",
      "         [ 0.4692,  0.0138],\n",
      "         [-0.0097, -0.1606],\n",
      "         [ 0.0105,  0.0089]]], grad_fn=<AddBackward0>), tensor([[[ 0.1191, -0.1842],\n",
      "         [ 1.0479,  0.2365],\n",
      "         [ 0.4248, -0.1409],\n",
      "         [ 0.0393, -0.1585],\n",
      "         [ 0.0070,  0.7503],\n",
      "         [ 0.3951, -0.0212],\n",
      "         [ 0.2930, -0.2872],\n",
      "         [-0.2793,  0.0311]]], grad_fn=<AddBackward0>), tensor([[[-0.2536,  0.1433],\n",
      "         [ 0.8185,  0.0778],\n",
      "         [-0.0442,  0.0520],\n",
      "         [ 0.3230, -0.1537],\n",
      "         [-0.1944,  0.3574],\n",
      "         [ 0.2521, -0.1613],\n",
      "         [-0.3700, -0.0528],\n",
      "         [-0.0234, -0.0439]]], grad_fn=<AddBackward0>), tensor([[[-0.0521, -0.3193],\n",
      "         [ 0.3175,  0.2622],\n",
      "         [ 0.3666,  0.2992],\n",
      "         [ 0.2842,  0.2172],\n",
      "         [ 0.1550,  0.3785],\n",
      "         [ 0.1427,  0.0231],\n",
      "         [ 0.3757,  0.0742],\n",
      "         [-0.2133, -0.0465]]], grad_fn=<AddBackward0>), tensor([[[-2.5479e-02,  4.1640e-01],\n",
      "         [-2.6980e-02,  1.6224e-01],\n",
      "         [-2.3556e-01, -1.2837e-01],\n",
      "         [ 9.3370e-02, -5.2277e-02],\n",
      "         [ 7.7955e-01,  3.1648e-01],\n",
      "         [-9.8855e-02, -1.7916e-04],\n",
      "         [-9.2079e-02,  2.4497e-01],\n",
      "         [ 6.9995e-02, -1.4098e-01]]], grad_fn=<AddBackward0>), tensor([[[ 0.0710,  0.3126],\n",
      "         [ 0.1327, -0.0052],\n",
      "         [ 0.1451, -0.2142],\n",
      "         [ 0.1712, -0.0341],\n",
      "         [-0.3403, -0.1225],\n",
      "         [ 0.2843, -0.2926],\n",
      "         [-0.6261,  0.3619],\n",
      "         [-0.2655, -0.0960]]], grad_fn=<AddBackward0>), tensor([[[ 0.0373,  0.0447],\n",
      "         [ 0.4361,  0.2002],\n",
      "         [ 0.1956, -0.0631],\n",
      "         [-0.1309,  0.0101],\n",
      "         [ 0.1811,  0.3926],\n",
      "         [ 0.2693, -0.1539],\n",
      "         [ 0.2179,  0.4981],\n",
      "         [-0.2685,  0.0571]]], grad_fn=<AddBackward0>), tensor([[[ 0.1289,  0.5419],\n",
      "         [ 0.2792,  0.1684],\n",
      "         [-0.0128, -0.2494],\n",
      "         [ 0.2117, -0.4675],\n",
      "         [ 0.1714, -0.0679],\n",
      "         [-0.1269, -0.2455],\n",
      "         [ 0.1124,  0.3605],\n",
      "         [-0.3133, -0.2006]]], grad_fn=<AddBackward0>), tensor([[[ 0.0115,  0.1201],\n",
      "         [ 0.0496, -0.5219],\n",
      "         [-0.0795, -0.0116],\n",
      "         [ 0.3392, -0.1740],\n",
      "         [ 0.2512,  0.2949],\n",
      "         [ 0.1019, -0.0077],\n",
      "         [ 0.7492,  0.5675],\n",
      "         [-0.1254, -0.0690]]], grad_fn=<AddBackward0>), tensor([[[ 0.0530, -0.0470],\n",
      "         [ 0.0900, -0.7036],\n",
      "         [ 0.2159, -0.0379],\n",
      "         [ 0.0179, -0.2615],\n",
      "         [-0.2129, -0.1453],\n",
      "         [-0.3118, -0.1732],\n",
      "         [ 0.1366,  0.2482],\n",
      "         [-0.0516, -0.0273]]], grad_fn=<AddBackward0>), tensor([[[-0.3288, -0.1809],\n",
      "         [-0.0235,  0.1577],\n",
      "         [ 0.1813, -0.1082],\n",
      "         [ 0.2311, -0.3957],\n",
      "         [ 0.2245,  0.0257],\n",
      "         [-0.3203,  0.0629],\n",
      "         [ 0.2210,  0.0720],\n",
      "         [-0.5973,  0.1385]]], grad_fn=<AddBackward0>)]\n"
     ]
    }
   ],
   "source": [
    "class BertForClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BertForClassification, self).__init__()\n",
    "        self.backbone = AutoModel.from_pretrained(\"../../module/bert-base-uncased\")\n",
    "        for p in self.parameters():\n",
    "            p.requires_grad = False  # freeze the backbone model\n",
    "        self.linear1 = nn.Linear(768, 256)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.linear2 = nn.Linear(256, 2)  # 2 is the number of classes in this example\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        backbone = self.backbone(input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
    "        # backbone has the following shape: (batch_size, sequence_length, 768)\n",
    "\n",
    "        # layer-wise\n",
    "        layers = list(backbone.hidden_states)\n",
    "        for i in range(len(backbone.hidden_states)):\n",
    "            l1 = self.linear1(backbone.hidden_states[i])\n",
    "            dropout = self.dropout(l1)\n",
    "            l2 = self.linear2(dropout)\n",
    "            layers[i] = l2\n",
    "        return layers\n",
    "\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "model = BertForClassification().forward(input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"])\n",
    "print(model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 72/100 [01:12<00:28,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 73/100 [01:13<00:27,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 74/100 [01:14<00:26,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 75/100 [01:15<00:25,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 76/100 [01:16<00:24,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 77/100 [01:17<00:23,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 78/100 [01:18<00:22,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 79/100 [01:20<00:21,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 80/100 [01:21<00:20,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 81/100 [01:22<00:19,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 82/100 [01:23<00:18,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 83/100 [01:24<00:17,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 84/100 [01:25<00:16,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 85/100 [01:26<00:15,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 86/100 [01:27<00:14,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 87/100 [01:28<00:13,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 88/100 [01:29<00:12,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 89/100 [01:30<00:11,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 90/100 [01:31<00:10,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 91/100 [01:32<00:09,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 92/100 [01:33<00:08,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 93/100 [01:34<00:07,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 94/100 [01:35<00:06,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 95/100 [01:36<00:05,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 96/100 [01:37<00:04,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 97/100 [01:38<00:03,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 98/100 [01:39<00:02,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [01:40<00:01,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [01:41<00:00,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/5 [01:41<?, ?it/s]\n",
      "\n",
      "  0%|          | 0/100 [00:01<?, ?it/s]\u001B[A\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'desc'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[1;32mIn [98]\u001B[0m, in \u001B[0;36m<cell line: 6>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m tqdm(\u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m100\u001B[39m)):\n\u001B[0;32m      7\u001B[0m     time\u001B[38;5;241m.\u001B[39msleep(\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m----> 8\u001B[0m     \u001B[43mtqdm\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mset_description\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mProcessing \u001B[39;49m\u001B[38;5;132;43;01m%s\u001B[39;49;00m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;241;43m%\u001B[39;49m\u001B[43mi\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\ProgramData\\Anaconda3\\envs\\bertology\\lib\\site-packages\\tqdm\\std.py:1406\u001B[0m, in \u001B[0;36mtqdm.set_description\u001B[1;34m(self, desc, refresh)\u001B[0m\n\u001B[0;32m   1396\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mset_description\u001B[39m(\u001B[38;5;28mself\u001B[39m, desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, refresh\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[0;32m   1397\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1398\u001B[0m \u001B[38;5;124;03m    Set/modify description of the progress bar.\u001B[39;00m\n\u001B[0;32m   1399\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1404\u001B[0m \u001B[38;5;124;03m        Forces refresh [default: True].\u001B[39;00m\n\u001B[0;32m   1405\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1406\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdesc \u001B[38;5;241m=\u001B[39m desc \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m: \u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m desc \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m   1407\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m refresh:\n\u001B[0;32m   1408\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrefresh()\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'str' object has no attribute 'desc'"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "pbar = tqdm([f\"Layer-{i}\" for i in range(5)])\n",
    "\n",
    "\n",
    "for i in tqdm(range(100)):\n",
    "    time.sleep(1)\n",
    "    tqdm.set_description(\"Processing %s\"%i)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}